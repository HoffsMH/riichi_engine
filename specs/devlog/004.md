# Devlog 004 - Bytes, Encoding, and the Display Pipeline

**Date:** 2026-02-10

## What Changed
- No code changes — pure conceptual session
- Updated CLAUDE.md devlog length to ~1 minute / 300 words

## Concepts Learned

### The display pipeline (memory to pixels)
- **Bytes have no inherent meaning** — the same byte is "A", a loudness level, or a temperature depending on what software reads it. Meaning is assigned by the *reader*, not stored in the byte
- **The full chain**: program writes bytes to stdout → terminal decodes UTF-8 → gets a code point number → asks font for a glyph → OS rasterizes vector shape to pixels → compositor sends to display
- Your C program only participates in the first step. Everything after is the terminal and OS

### Unicode and UTF-8 are separate things
- **Unicode** is a table mapping numbers (code points) to characters. Code point = just an index, like a street address. Range: 0 to 0x10FFFF
- **UTF-8** is one encoding scheme for serializing code points into bytes. UTF-16 and UTF-32 are alternatives
- Not stacked or nested — UTF-8 is a *serialization format* for Unicode's abstract numbers

### How UTF-8 actually works
- Variable width: 1–4 bytes per character depending on code point size
- Leading byte prefix: count the 1s before the first 0 to get total byte count (`110` = 2 bytes, `1110` = 3, `11110` = 4, `0` = 1/ASCII)
- Continuation bytes always start `10` — can never be confused with a leading byte
- The `x` bit slots get filled with the code point's binary representation
- Example: 0x1F004 (red dragon) → `11110 000 10 011111 10 000000 10 000100` → bytes `0xF0 0x9F 0x80 0x84`

### Why printf needs format specifiers
- C erases types at compile time — printf receives raw bytes and needs `%d`/`%c`/`%s` to know how to interpret them
- Ruby carries type tags at runtime (automatic but costly). C made you specify (manual but zero overhead)

### Testing in C
- Surveyed Git, SQLite, Postgres — all roll their own test infrastructure, no off-the-shelf framework dominates
- **assert()** is a crash-on-false macro from `<assert.h>`, not a testing tool — documents assumptions, costs one comparison, compiled away with `NDEBUG`
- Decision: skip unit test frameworks for now, test via running the binary, consider custom external testing later

## Next Steps
- Map mahjong tile suits/values to Unicode code points (domain logic)
- Implement UTF-8 encoding (bit shifting into prefix slots)
- Test by running the binary and checking output visually
